{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/usr/local/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "proposal_df = pd.read_excel('data/pycon_2024_proposal.xlsx', engine=\"openpyxl\")\n",
    "reviews_df = pd.read_excel('data/pycon_2024_review.xlsx', engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_df.id.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 RPM\n",
    "proposal_info_columns = [ 'title'\n",
    "  , 'abstract'\n",
    "  , 'detailed_description'\n",
    "  , 'outline'\n",
    "  , 'objective']\n",
    "\n",
    "result = []\n",
    "\n",
    "with open(\"prompt/simple_prompt_david.txt\", \"r\") as f:\n",
    "    prompt = f.read()\n",
    "prompt = PromptTemplate(input_variables=['PROPOSAL_INFO'],template=prompt)\n",
    "\n",
    "#model = \"gemini-2.0-pro-exp-02-05\"\n",
    "model = \"gemini-2.0-flash-exp\"\n",
    "fixing_model = \"gemini-2.0-flash-thinking-exp-01-21\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=model, temperature=0)\n",
    "fixing_llm = ChatGoogleGenerativeAI(model=fixing_model, temperature=0)\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "fixing_parser = OutputFixingParser.from_llm(\n",
    "    parser=json_parser,\n",
    "    llm=fixing_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = prompt | llm | StrOutputParser()\n",
    "# proposal_info = proposal_df[proposal_info_columns].to_dict(orient='records')[0]\n",
    "# executive_method = chain.invoke({\"PROPOSAL_INFO\": str(proposal_info)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing proposal: 2178936233474917120\n",
      "Execution time for proposal 2178936233474917120: 2.30 seconds\n",
      "\n",
      "Processing proposal: 2178979854999880448\n",
      "Execution time for proposal 2178979854999880448: 2.26 seconds\n",
      "\n",
      "Processing proposal: 2178981707884004096\n",
      "Execution time for proposal 2178981707884004096: 2.15 seconds\n",
      "\n",
      "Processing proposal: 2179613228097602304\n",
      "Execution time for proposal 2179613228097602304: 2.05 seconds\n",
      "\n",
      "Processing proposal: 2180814504890204928\n",
      "Execution time for proposal 2180814504890204928: 3.80 seconds\n",
      "\n",
      "Processing proposal: 2181661100230050560\n",
      "Execution time for proposal 2181661100230050560: 2.34 seconds\n",
      "\n",
      "Processing proposal: 2181767915890541312\n",
      "Execution time for proposal 2181767915890541312: 2.56 seconds\n",
      "\n",
      "Processing proposal: 2183455404749488896\n",
      "Execution time for proposal 2183455404749488896: 2.46 seconds\n",
      "\n",
      "Processing proposal: 2184258951825064704\n",
      "Execution time for proposal 2184258951825064704: 1.94 seconds\n",
      "\n",
      "Processing proposal: 2184265081062163200\n",
      "Execution time for proposal 2184265081062163200: 2.25 seconds\n",
      "\n",
      "Processing proposal: 2184271553351385856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2184271553351385856: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2184271553351385856: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2184271553351385856: 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2184271553351385856: 42.02 seconds\n",
      "\n",
      "Processing proposal: 2185842091785978624\n",
      "Execution time for proposal 2185842091785978624: 2.63 seconds\n",
      "\n",
      "Processing proposal: 2185844604283126528\n",
      "Execution time for proposal 2185844604283126528: 2.05 seconds\n",
      "\n",
      "Processing proposal: 2185845802830660352\n",
      "Execution time for proposal 2185845802830660352: 2.02 seconds\n",
      "\n",
      "Processing proposal: 2185846315039064832\n",
      "Execution time for proposal 2185846315039064832: 2.09 seconds\n",
      "\n",
      "Processing proposal: 2186438925994689280\n",
      "Execution time for proposal 2186438925994689280: 3.29 seconds\n",
      "\n",
      "Processing proposal: 2186443284254032640\n",
      "Execution time for proposal 2186443284254032640: 3.58 seconds\n",
      "\n",
      "Processing proposal: 2186467836912730880\n",
      "Execution time for proposal 2186467836912730880: 2.03 seconds\n",
      "\n",
      "Processing proposal: 2188433923833332480\n",
      "Execution time for proposal 2188433923833332480: 2.77 seconds\n",
      "\n",
      "Processing proposal: 2188525315913941760\n",
      "Execution time for proposal 2188525315913941760: 2.66 seconds\n",
      "\n",
      "Processing proposal: 2189264747189240576\n",
      "Execution time for proposal 2189264747189240576: 3.28 seconds\n",
      "\n",
      "Processing proposal: 2189388256229982976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2189388256229982976: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2189388256229982976: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2189388256229982976: 31.94 seconds\n",
      "\n",
      "Processing proposal: 2192450893792674560\n",
      "Execution time for proposal 2192450893792674560: 4.02 seconds\n",
      "\n",
      "Processing proposal: 2192916629635990272\n",
      "Execution time for proposal 2192916629635990272: 2.34 seconds\n",
      "\n",
      "Processing proposal: 2192921804903809792\n",
      "Execution time for proposal 2192921804903809792: 2.39 seconds\n",
      "\n",
      "Processing proposal: 2194950561579664128\n",
      "Execution time for proposal 2194950561579664128: 3.26 seconds\n",
      "\n",
      "Processing proposal: 2195629600740999936\n",
      "Execution time for proposal 2195629600740999936: 4.14 seconds\n",
      "\n",
      "Processing proposal: 2195682525014131456\n",
      "Execution time for proposal 2195682525014131456: 2.79 seconds\n",
      "\n",
      "Processing proposal: 2195793247056429824\n",
      "Execution time for proposal 2195793247056429824: 3.30 seconds\n",
      "\n",
      "Processing proposal: 2197219917860700928\n",
      "Execution time for proposal 2197219917860700928: 2.76 seconds\n",
      "\n",
      "Processing proposal: 2197262136667800320\n",
      "Execution time for proposal 2197262136667800320: 3.26 seconds\n",
      "\n",
      "Processing proposal: 2197952451796009728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2197952451796009728: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2197952451796009728: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2197952451796009728: 29.40 seconds\n",
      "\n",
      "Processing proposal: 2198581276154266368\n",
      "Execution time for proposal 2198581276154266368: 3.39 seconds\n",
      "\n",
      "Processing proposal: 2201589261063422720\n",
      "Execution time for proposal 2201589261063422720: 2.55 seconds\n",
      "\n",
      "Processing proposal: 2201815482904871680\n",
      "Execution time for proposal 2201815482904871680: 2.15 seconds\n",
      "\n",
      "Processing proposal: 2202583607111844608\n",
      "Basic parser failed, attempting fix: Invalid json output: ```json\n",
      "{\n",
      "  \"comment\": \"This proposal outlines a session on using Python CDK for infrastructure deployment on AWS. The abstract clearly states the problem being addressed (manual resource provisioning) and the proposed solution (IaC with Python CDK). The detailed description provides a good overview of the session's content, including an introduction to CDK, its benefits, and a demo. The outline is well-structured and provides a reasonable breakdown of the session's topics and timings. The objective clearly articulates the benefits of using Python CDK for IaC, such as environment replication, reduced complexity, and improved consistency. \\n\\n**Strengths:**\\n*   Clear problem statement and proposed solution.\\n*   Well-defined session outline.\\n*   Good explanation of the benefits of using Python CDK.\\n*   Includes a demo, which is valuable for attendees.\\n\\n**Areas for Improvement:**\\n*   The abstract and detailed description could be more concise and focused. Consider removing redundant phrases.\\n*   The outline could benefit from more specific examples of best practices and real-world use cases.  Instead of just stating \"Best Practices\" and \"Real-world Use Cases,\" provide a brief preview of what those will entail. For example, under \"Best Practices,\" you could add: \\\"Share CDK's best practices and tips (e.g., using constructs, managing dependencies).\\\"\\n*   Consider adding a target audience section to clarify who would benefit most from this session (e.g., developers, DevOps engineers, cloud architects).\\n\\nOverall, this is a solid proposal with the potential to be a valuable session for attendees interested in IaC and AWS CDK.\",\n",
      "  \"vote\": \"+1\"\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Execution time for proposal 2202583607111844608: 4.87 seconds\n",
      "\n",
      "Processing proposal: 2202977686752592640\n",
      "Execution time for proposal 2202977686752592640: 2.90 seconds\n",
      "\n",
      "Processing proposal: 2203075043099935488\n",
      "Execution time for proposal 2203075043099935488: 3.20 seconds\n",
      "\n",
      "Processing proposal: 2204392707969778432\n",
      "Execution time for proposal 2204392707969778432: 4.39 seconds\n",
      "\n",
      "Processing proposal: 2205027665625219840\n",
      "Execution time for proposal 2205027665625219840: 2.67 seconds\n",
      "\n",
      "Processing proposal: 2205136900467983104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2205136900467983104: 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2205136900467983104: 14.93 seconds\n",
      "\n",
      "Processing proposal: 2205248731861746432\n",
      "Execution time for proposal 2205248731861746432: 2.25 seconds\n",
      "\n",
      "Processing proposal: 2205337041422516992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2205337041422516992: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2205337041422516992: 16.90 seconds\n",
      "\n",
      "Processing proposal: 2206153743848702720\n",
      "Execution time for proposal 2206153743848702720: 3.34 seconds\n",
      "\n",
      "Processing proposal: 2206556565719220992\n",
      "Execution time for proposal 2206556565719220992: 2.52 seconds\n",
      "\n",
      "Processing proposal: 2206896476334850816\n",
      "Execution time for proposal 2206896476334850816: 4.31 seconds\n",
      "\n",
      "Processing proposal: 2206984221174530816\n",
      "Execution time for proposal 2206984221174530816: 1.93 seconds\n",
      "\n",
      "Processing proposal: 2207288307711214336\n",
      "Execution time for proposal 2207288307711214336: 2.86 seconds\n",
      "\n",
      "Processing proposal: 2208409881428361984\n",
      "Execution time for proposal 2208409881428361984: 2.46 seconds\n",
      "\n",
      "Processing proposal: 2208578622766187264\n",
      "Execution time for proposal 2208578622766187264: 3.42 seconds\n",
      "\n",
      "Processing proposal: 2208789199635612416\n",
      "Execution time for proposal 2208789199635612416: 4.78 seconds\n",
      "\n",
      "Processing proposal: 2208992563552060160\n",
      "Execution time for proposal 2208992563552060160: 3.38 seconds\n",
      "\n",
      "Processing proposal: 2209033186929804032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2209033186929804032: 2.39 seconds\n",
      "\n",
      "Processing proposal: 2209040357629362944\n",
      "LLM or parsing failed for proposal 2209040357629362944: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2209040357629362944: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2209040357629362944: 30.10 seconds\n",
      "\n",
      "Processing proposal: 2209120431347073792\n",
      "Execution time for proposal 2209120431347073792: 2.10 seconds\n",
      "\n",
      "Processing proposal: 2209123047938458368\n",
      "Execution time for proposal 2209123047938458368: 2.61 seconds\n",
      "\n",
      "Processing proposal: 2209155308083741440\n",
      "Execution time for proposal 2209155308083741440: 3.64 seconds\n",
      "\n",
      "Processing proposal: 2209459737420890880\n",
      "Execution time for proposal 2209459737420890880: 4.15 seconds\n",
      "\n",
      "Processing proposal: 2209507247787082496\n",
      "Execution time for proposal 2209507247787082496: 3.47 seconds\n",
      "\n",
      "Processing proposal: 2209587078117720832\n",
      "Execution time for proposal 2209587078117720832: 4.59 seconds\n",
      "\n",
      "Processing proposal: 2209677975304012544\n",
      "Execution time for proposal 2209677975304012544: 2.55 seconds\n",
      "\n",
      "Processing proposal: 2210220044032410368\n",
      "Execution time for proposal 2210220044032410368: 3.72 seconds\n",
      "\n",
      "Processing proposal: 2210288503076422400\n",
      "Execution time for proposal 2210288503076422400: 2.86 seconds\n",
      "\n",
      "Processing proposal: 2210341851536294656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2210341851536294656: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2210341851536294656: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2210341851536294656: 30.21 seconds\n",
      "\n",
      "Processing proposal: 2210394752925303552\n",
      "Execution time for proposal 2210394752925303552: 2.74 seconds\n",
      "\n",
      "Processing proposal: 2210405674750313216\n",
      "Execution time for proposal 2210405674750313216: 2.15 seconds\n",
      "\n",
      "Processing proposal: 2210432102875267840\n",
      "Execution time for proposal 2210432102875267840: 3.49 seconds\n",
      "\n",
      "Processing proposal: 2210433720316330752\n",
      "Execution time for proposal 2210433720316330752: 3.42 seconds\n",
      "\n",
      "Processing proposal: 2210443378934416128\n",
      "Execution time for proposal 2210443378934416128: 2.35 seconds\n",
      "\n",
      "Processing proposal: 2210457031310050048\n",
      "Execution time for proposal 2210457031310050048: 2.21 seconds\n",
      "\n",
      "Processing proposal: 2210461538760786688\n",
      "Execution time for proposal 2210461538760786688: 5.62 seconds\n",
      "\n",
      "Processing proposal: 2210513372791702272\n",
      "Execution time for proposal 2210513372791702272: 3.34 seconds\n",
      "\n",
      "Processing proposal: 2210517591254893312\n",
      "Execution time for proposal 2210517591254893312: 2.84 seconds\n",
      "\n",
      "Processing proposal: 2210697815674323712\n",
      "Execution time for proposal 2210697815674323712: 2.40 seconds\n",
      "\n",
      "Processing proposal: 2210750583986455296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2210750583986455296: 4.55 seconds\n",
      "\n",
      "Processing proposal: 2210778103544808192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2210778103544808192: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM or parsing failed for proposal 2210778103544808192: 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2210778103544808192: 27.77 seconds\n",
      "\n",
      "Processing proposal: 2211064418454733568\n",
      "Execution time for proposal 2211064418454733568: 2.50 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 建立原始的 JsonOutputParser 和 fixing parser\n",
    "processed_proposals = set(r.get('proposal_id') for r in result)\n",
    "\n",
    "for proposal_id in proposal_df.id:\n",
    "    start_time = time.time()\n",
    "    if proposal_id in processed_proposals:\n",
    "        print(f\"Skipping already processed proposal: {proposal_id}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing proposal: {proposal_id}\")\n",
    "    proposal_info = proposal_df[proposal_df.id == proposal_id][proposal_info_columns].to_dict(orient='records')[0]\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get raw output from LLM first\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            raw_output = chain.invoke({\"PROPOSAL_INFO\": str(proposal_info)})\n",
    "            \n",
    "            try:\n",
    "                # Try basic JSON parser first\n",
    "                executive_method = json_parser.parse(raw_output)\n",
    "            except Exception as e:\n",
    "                print(f\"Basic parser failed, attempting fix: {e}\")\n",
    "                # If basic parser fails, use fixing parser on the same output\n",
    "                executive_method = fixing_parser.parse(raw_output)\n",
    "            \n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"LLM or parsing failed for proposal {proposal_id}: {e}\")\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "    \n",
    "    executive_method['proposal_id'] = proposal_id\n",
    "    result.append(executive_method)\n",
    "    \n",
    "    exec_time = time.time() - start_time\n",
    "    print(f\"Execution time for proposal {proposal_id}: {exec_time:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'+1': 49, '+0': 18, '0': 9, '-0': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each proposal_id\n",
    "Counter(r['vote'] for r in result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'comment': \"The proposal is well-structured and clearly outlines the benefits of using Python CDK for infrastructure deployment. The inclusion of a demo is a great way to engage the audience. Consider adding more specific examples of best practices and real-world use cases to enhance the session's practical value.\",\n",
       "  'vote': '+1',\n",
       "  'proposal_id': 2202583607111844608}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ x for x in result if x['proposal_id'] == 2202583607111844608 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>duration</th>\n",
       "      <th>language</th>\n",
       "      <th>abstract</th>\n",
       "      <th>python_level</th>\n",
       "      <th>detailed_description</th>\n",
       "      <th>outline</th>\n",
       "      <th>supplementary</th>\n",
       "      <th>...</th>\n",
       "      <th>conference</th>\n",
       "      <th>last_updated_at</th>\n",
       "      <th>slido_embed_link</th>\n",
       "      <th>referring_policy</th>\n",
       "      <th>labels</th>\n",
       "      <th>first_time_speaker</th>\n",
       "      <th>live_stream_policy</th>\n",
       "      <th>hackmd_embed_link</th>\n",
       "      <th>living_in_taiwan</th>\n",
       "      <th>attend_in_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2202583607111844608</td>\n",
       "      <td>Driving Efficiency through Automation: Leverag...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>PREF15</td>\n",
       "      <td>ENEN</td>\n",
       "      <td>Efficiently tackling some of the resource prov...</td>\n",
       "      <td>INTERMEDIATE</td>\n",
       "      <td>During this session, I'll provide a comprehens...</td>\n",
       "      <td>1. Introduction: (2 minutes)\\r\\n   .  Briefly ...</td>\n",
       "      <td>First and foremost, I want to express my grati...</td>\n",
       "      <td>...</td>\n",
       "      <td>pycontw-2024</td>\n",
       "      <td>2024-05-20 16:25:00.208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                              title  \\\n",
       "35  2202583607111844608  Driving Efficiency through Automation: Leverag...   \n",
       "\n",
       "   category duration language  \\\n",
       "35    OTHER   PREF15     ENEN   \n",
       "\n",
       "                                             abstract  python_level  \\\n",
       "35  Efficiently tackling some of the resource prov...  INTERMEDIATE   \n",
       "\n",
       "                                 detailed_description  \\\n",
       "35  During this session, I'll provide a comprehens...   \n",
       "\n",
       "                                              outline  \\\n",
       "35  1. Introduction: (2 minutes)\\r\\n   .  Briefly ...   \n",
       "\n",
       "                                        supplementary  ...    conference  \\\n",
       "35  First and foremost, I want to express my grati...  ...  pycontw-2024   \n",
       "\n",
       "           last_updated_at  slido_embed_link referring_policy labels  \\\n",
       "35 2024-05-20 16:25:00.208               NaN             True    NaN   \n",
       "\n",
       "    first_time_speaker  live_stream_policy hackmd_embed_link living_in_taiwan  \\\n",
       "35                True                True               NaN            False   \n",
       "\n",
       "   attend_in_person  \n",
       "35             True  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_df[proposal_df.id == 2202583607111844608]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
