{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#reload the api key if you want to use a different api key\n",
    "#load_dotenv(override=True)\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "proposal_df = pd.read_excel('data/pycon_2024_proposal.xlsx', dtype={'id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_df.id.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the prompt file and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompt_file = \"prompt/simple_prompt.txt\"\n",
    "full_prompt_file = \"prompt/full_prompt.txt\"\n",
    "\n",
    "flash_model = \"gemini-2.0-flash-exp\"\n",
    "pro_model = \"gemini-2.0-pro-exp-02-05\"\n",
    "\n",
    "exec_prompt = full_prompt_file\n",
    "exec_model = flash_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_info_columns = [ 'title'\n",
    "  , 'abstract'\n",
    "  , 'detailed_description'\n",
    "  , 'outline'\n",
    "  , 'objective']\n",
    "\n",
    "class ProposalReview(BaseModel):\n",
    "    \"\"\"Review for a PyCon proposal\"\"\"\n",
    "    summary: str\n",
    "    comment: str\n",
    "    vote: Literal['+1', '+0', '-0', '-1']\n",
    "\n",
    "with open(exec_prompt, \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['PROPOSAL_INFO'], template=prompt_template)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=exec_model, temperature=0)\n",
    "structured_llm = llm.with_structured_output(ProposalReview)\n",
    "chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "sleep_time = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing proposal: 2178936233474917120\n",
      "Execution time for proposal 2178936233474917120: 3.79 seconds\n",
      "\n",
      "Processing proposal: 2178979854999880448\n",
      "Execution time for proposal 2178979854999880448: 2.45 seconds\n",
      "\n",
      "Processing proposal: 2178981707884004096\n",
      "Execution time for proposal 2178981707884004096: 3.00 seconds\n",
      "\n",
      "Processing proposal: 2179613228097602304\n",
      "Execution time for proposal 2179613228097602304: 2.34 seconds\n",
      "\n",
      "Processing proposal: 2180814504890204928\n",
      "Execution time for proposal 2180814504890204928: 2.65 seconds\n",
      "\n",
      "Processing proposal: 2181661100230050560\n",
      "Execution time for proposal 2181661100230050560: 2.87 seconds\n",
      "\n",
      "Processing proposal: 2181767915890541312\n",
      "Execution time for proposal 2181767915890541312: 3.48 seconds\n",
      "\n",
      "Processing proposal: 2183455404749488896\n",
      "Execution time for proposal 2183455404749488896: 1.94 seconds\n",
      "\n",
      "Processing proposal: 2184258951825064704\n",
      "Execution time for proposal 2184258951825064704: 2.57 seconds\n",
      "\n",
      "Processing proposal: 2184265081062163200\n",
      "Execution time for proposal 2184265081062163200: 2.36 seconds\n",
      "\n",
      "Processing proposal: 2184271553351385856\n",
      "Execution time for proposal 2184271553351385856: 1.94 seconds\n",
      "\n",
      "Processing proposal: 2185842091785978624\n",
      "Execution time for proposal 2185842091785978624: 2.15 seconds\n",
      "\n",
      "Processing proposal: 2185844604283126528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM invoke failed for proposal 2185844604283126528 (Attempt 1/6): 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2185844604283126528: 25.08 seconds\n",
      "\n",
      "Processing proposal: 2185845802830660352\n",
      "Execution time for proposal 2185845802830660352: 2.46 seconds\n",
      "\n",
      "Processing proposal: 2185846315039064832\n",
      "Execution time for proposal 2185846315039064832: 2.46 seconds\n",
      "\n",
      "Processing proposal: 2186438925994689280\n",
      "Execution time for proposal 2186438925994689280: 2.36 seconds\n",
      "\n",
      "Processing proposal: 2186443284254032640\n",
      "Execution time for proposal 2186443284254032640: 2.46 seconds\n",
      "\n",
      "Processing proposal: 2186467836912730880\n",
      "Execution time for proposal 2186467836912730880: 2.56 seconds\n",
      "\n",
      "Processing proposal: 2188433923833332480\n",
      "Execution time for proposal 2188433923833332480: 2.05 seconds\n",
      "\n",
      "Processing proposal: 2188525315913941760\n",
      "Execution time for proposal 2188525315913941760: 2.56 seconds\n",
      "\n",
      "Processing proposal: 2189264747189240576\n",
      "Execution time for proposal 2189264747189240576: 2.45 seconds\n",
      "\n",
      "Processing proposal: 2189388256229982976\n",
      "Execution time for proposal 2189388256229982976: 2.72 seconds\n",
      "\n",
      "Processing proposal: 2192450893792674560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM invoke failed for proposal 2192450893792674560 (Attempt 1/6): 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2192450893792674560: 27.15 seconds\n",
      "\n",
      "Processing proposal: 2192916629635990272\n",
      "Execution time for proposal 2192916629635990272: 2.28 seconds\n",
      "\n",
      "Processing proposal: 2192921804903809792\n",
      "Execution time for proposal 2192921804903809792: 2.54 seconds\n",
      "\n",
      "Processing proposal: 2194950561579664128\n",
      "Execution time for proposal 2194950561579664128: 2.81 seconds\n",
      "\n",
      "Processing proposal: 2195629600740999936\n",
      "Execution time for proposal 2195629600740999936: 2.95 seconds\n",
      "\n",
      "Processing proposal: 2195682525014131456\n",
      "Execution time for proposal 2195682525014131456: 2.97 seconds\n",
      "\n",
      "Processing proposal: 2195793247056429824\n",
      "Execution time for proposal 2195793247056429824: 2.77 seconds\n",
      "\n",
      "Processing proposal: 2197219917860700928\n",
      "Execution time for proposal 2197219917860700928: 2.66 seconds\n",
      "\n",
      "Processing proposal: 2197262136667800320\n",
      "Execution time for proposal 2197262136667800320: 2.44 seconds\n",
      "\n",
      "Processing proposal: 2197952451796009728\n",
      "Execution time for proposal 2197952451796009728: 2.26 seconds\n",
      "\n",
      "Processing proposal: 2198581276154266368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM invoke failed for proposal 2198581276154266368 (Attempt 1/6): 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for proposal 2198581276154266368: 27.65 seconds\n",
      "\n",
      "Processing proposal: 2201589261063422720\n",
      "Execution time for proposal 2201589261063422720: 2.46 seconds\n",
      "\n",
      "Processing proposal: 2201815482904871680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM invoke failed for proposal 2201815482904871680 (Attempt 1/6): 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2201815482904871680: 26.21 seconds\n",
      "\n",
      "Processing proposal: 2202583607111844608\n",
      "Execution time for proposal 2202583607111844608: 2.26 seconds\n",
      "\n",
      "Processing proposal: 2202977686752592640\n",
      "Execution time for proposal 2202977686752592640: 2.56 seconds\n",
      "\n",
      "Processing proposal: 2203075043099935488\n",
      "Execution time for proposal 2203075043099935488: 2.15 seconds\n",
      "\n",
      "Processing proposal: 2204392707969778432\n",
      "Execution time for proposal 2204392707969778432: 2.76 seconds\n",
      "\n",
      "Processing proposal: 2205027665625219840\n",
      "Execution time for proposal 2205027665625219840: 3.69 seconds\n",
      "\n",
      "Processing proposal: 2205136900467983104\n",
      "Execution time for proposal 2205136900467983104: 3.02 seconds\n",
      "\n",
      "Processing proposal: 2205248731861746432\n",
      "Execution time for proposal 2205248731861746432: 2.71 seconds\n",
      "\n",
      "Processing proposal: 2205337041422516992\n",
      "Execution time for proposal 2205337041422516992: 2.36 seconds\n",
      "\n",
      "Processing proposal: 2206153743848702720\n",
      "Execution time for proposal 2206153743848702720: 2.66 seconds\n",
      "\n",
      "Processing proposal: 2206556565719220992\n",
      "Execution time for proposal 2206556565719220992: 2.56 seconds\n",
      "\n",
      "Processing proposal: 2206896476334850816\n",
      "Execution time for proposal 2206896476334850816: 2.65 seconds\n",
      "\n",
      "Processing proposal: 2206984221174530816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM invoke failed for proposal 2206984221174530816 (Attempt 1/6): 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2206984221174530816: 25.24 seconds\n",
      "\n",
      "Processing proposal: 2207288307711214336\n",
      "Execution time for proposal 2207288307711214336: 2.66 seconds\n",
      "\n",
      "Processing proposal: 2208409881428361984\n",
      "Execution time for proposal 2208409881428361984: 2.94 seconds\n",
      "\n",
      "Processing proposal: 2208578622766187264\n",
      "Execution time for proposal 2208578622766187264: 2.15 seconds\n",
      "\n",
      "Processing proposal: 2208789199635612416\n",
      "Execution time for proposal 2208789199635612416: 3.07 seconds\n",
      "\n",
      "Processing proposal: 2208992563552060160\n",
      "Execution time for proposal 2208992563552060160: 3.38 seconds\n",
      "\n",
      "Processing proposal: 2209033186929804032\n",
      "Execution time for proposal 2209033186929804032: 2.26 seconds\n",
      "\n",
      "Processing proposal: 2209040357629362944\n",
      "Execution time for proposal 2209040357629362944: 2.66 seconds\n",
      "\n",
      "Processing proposal: 2209120431347073792\n",
      "Execution time for proposal 2209120431347073792: 2.98 seconds\n",
      "\n",
      "Processing proposal: 2209123047938458368\n",
      "Execution time for proposal 2209123047938458368: 3.37 seconds\n",
      "\n",
      "Processing proposal: 2209155308083741440\n",
      "Execution time for proposal 2209155308083741440: 2.55 seconds\n",
      "\n",
      "Processing proposal: 2209459737420890880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM invoke failed for proposal 2209459737420890880 (Attempt 1/6): 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2209459737420890880: 25.01 seconds\n",
      "\n",
      "Processing proposal: 2209507247787082496\n",
      "Execution time for proposal 2209507247787082496: 2.04 seconds\n",
      "\n",
      "Processing proposal: 2209587078117720832\n",
      "Execution time for proposal 2209587078117720832: 3.84 seconds\n",
      "\n",
      "Processing proposal: 2209677975304012544\n",
      "Execution time for proposal 2209677975304012544: 3.02 seconds\n",
      "\n",
      "Processing proposal: 2210220044032410368\n",
      "Execution time for proposal 2210220044032410368: 2.56 seconds\n",
      "\n",
      "Processing proposal: 2210288503076422400\n",
      "Execution time for proposal 2210288503076422400: 2.66 seconds\n",
      "\n",
      "Processing proposal: 2210341851536294656\n",
      "Execution time for proposal 2210341851536294656: 2.40 seconds\n",
      "\n",
      "Processing proposal: 2210394752925303552\n",
      "Execution time for proposal 2210394752925303552: 2.61 seconds\n",
      "\n",
      "Processing proposal: 2210405674750313216\n",
      "Execution time for proposal 2210405674750313216: 2.54 seconds\n",
      "\n",
      "Processing proposal: 2210432102875267840\n",
      "Execution time for proposal 2210432102875267840: 2.44 seconds\n",
      "\n",
      "Processing proposal: 2210433720316330752\n",
      "Execution time for proposal 2210433720316330752: 2.99 seconds\n",
      "\n",
      "Processing proposal: 2210443378934416128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM invoke failed for proposal 2210443378934416128 (Attempt 1/6): 429 Resource has been exhausted (e.g. check quota).\n",
      "Execution time for proposal 2210443378934416128: 24.59 seconds\n",
      "\n",
      "Processing proposal: 2210457031310050048\n",
      "Execution time for proposal 2210457031310050048: 2.88 seconds\n",
      "\n",
      "Processing proposal: 2210461538760786688\n",
      "Execution time for proposal 2210461538760786688: 3.47 seconds\n",
      "\n",
      "Processing proposal: 2210513372791702272\n",
      "Execution time for proposal 2210513372791702272: 2.73 seconds\n",
      "\n",
      "Processing proposal: 2210517591254893312\n",
      "Execution time for proposal 2210517591254893312: 2.74 seconds\n",
      "\n",
      "Processing proposal: 2210697815674323712\n",
      "Execution time for proposal 2210697815674323712: 2.93 seconds\n",
      "\n",
      "Processing proposal: 2210750583986455296\n",
      "Execution time for proposal 2210750583986455296: 2.67 seconds\n",
      "\n",
      "Processing proposal: 2210778103544808192\n",
      "Execution time for proposal 2210778103544808192: 2.35 seconds\n",
      "\n",
      "Processing proposal: 2211064418454733568\n",
      "Execution time for proposal 2211064418454733568: 2.24 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_proposals = set(r.get('proposal_id') for r in result)\n",
    "\n",
    "for proposal_id in proposal_df.id:\n",
    "    start_time = time.time()\n",
    "    if proposal_id in processed_proposals:\n",
    "        print(f\"Skipping already processed proposal: {proposal_id}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing proposal: {proposal_id}\")\n",
    "    proposal_info = proposal_df[proposal_df.id == proposal_id][proposal_info_columns].to_dict(orient='records')[0]\n",
    "    \n",
    "    max_retries = 6\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            review = chain.invoke({\"PROPOSAL_INFO\": str(proposal_info)})\n",
    "            review_dict = review.model_dump()\n",
    "            review_dict['proposal_id'] = proposal_id\n",
    "            result.append(review_dict)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"LLM invoke failed for proposal {proposal_id} (Attempt {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise Exception(f\"Max retries ({max_retries}) exceeded for proposal {proposal_id}\")\n",
    "            time.sleep(sleep_time)\n",
    "    \n",
    "    exec_time = time.time() - start_time\n",
    "    print(f\"Execution time for proposal {proposal_id}: {exec_time:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'+0': 66, '+1': 8, '-0': 3})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(r.get('vote') for r in result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice! int may cause overflow\n",
    "\n",
    "# simple_df = pd.DataFrame(result)\n",
    "# simple_df['proposal_id'] = simple_df['proposal_id'].astype(str)\n",
    "# simple_df.to_excel('data/simple_prompt_gemini_flash_0216.xlsx', index=False)\n",
    "\n",
    "complete_df = pd.DataFrame(result)\n",
    "complete_df['proposal_id'] = complete_df['proposal_id'].astype(str)\n",
    "complete_df.to_excel('data/full_prompt_gemini_flash_0216.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
